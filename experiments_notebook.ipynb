{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiable SFC: Experiments X1-X5\n",
    "\n",
    "A comprehensive notebook demonstrating the progression from simple SIM models to full climate-integrated Green-SFC with variable β annealing.\n",
    "\n",
    "**Navigation:** Each experiment is in its own section below. Use the notebook outline to collapse/expand experiments.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Import all required libraries and configure matplotlib for interactive plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Configure matplotlib\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X1: Differentiable SIM Model (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### X1: Model Definition & Training\n\n# X1: Differentiable SIM Model (PyTorch)\n# Implementation of the classic Service-Induced Macroeconomic (SIM) model\n# with automatic differentiation for policy optimization\n\nclass SIM_Model(nn.Module):\n    \"\"\"Differentiable SIM Model with learnable behavioral parameters.\"\"\"\n    \n    def __init__(self, steps=100):\n        super(SIM_Model, self).__init__()\n        self.steps = steps\n        \n        # Behavioral Parameters (Learnable)\n        self.alpha1 = nn.Parameter(torch.tensor(0.6))  # Propensity to consume (income)\n        self.alpha2 = nn.Parameter(torch.tensor(0.4))  # Propensity to consume (wealth)\n        \n        # Policy Knob: The Tax Rate (theta)\n        self.theta = nn.Parameter(torch.tensor(0.15))\n        \n        # Exogenous Variable: Government Spending\n        self.G = torch.tensor(20.0)\n\n    def forward(self, h_initial):\n        \"\"\"Run SIM model for self.steps timesteps.\"\"\"\n        h = h_initial\n        y_history = []\n        h_history = []\n        \n        for t in range(self.steps):\n            # SFC Identities (SIM Model)\n            # Y = (G + a2*H_prev) / (1 - a1*(1 - theta))\n            denominator = 1 - self.alpha1 * (1 - self.theta)\n            y = (self.G + self.alpha2 * h) / denominator\n            \n            t_tax = self.theta * y\n            yd = y - t_tax\n            c = self.alpha1 * yd + self.alpha2 * h\n            \n            # Update Stock: Delta H = YD - C\n            h = h + (yd - c)\n            \n            y_history.append(y)\n            h_history.append(h)\n            \n        return torch.stack(y_history), torch.stack(h_history)\n\n\n# Run X1 Experiment\nprint(\"X1: Differentiable SIM Model Optimization\")\nprint(\"=\" * 60)\n\nmodel_x1 = SIM_Model(steps=50)\noptimizer_x1 = optim.Adam(model_x1.parameters(), lr=0.01)\n\nprint(\"Starting Policy Optimization...\\n\")\nlosses_x1 = []\ntax_rates_x1 = []\n\nfor epoch in range(200):\n    optimizer_x1.zero_grad()\n    \n    h0 = torch.tensor(10.0)\n    y_hist, h_hist = model_x1(h0)\n    \n    # Multi-objective Loss\n    gap_loss = torch.mean((y_hist - 100.0)**2)\n    growth_rate = y_hist[1:] / y_hist[:-1] - 1\n    volatility_loss = torch.var(growth_rate) * 1000\n    wealth_drift = torch.abs(h_hist[-1] - h_hist[0])\n    \n    loss = gap_loss + volatility_loss + (0.1 * wealth_drift)\n    \n    loss.backward()\n    optimizer_x1.step()\n    \n    # Constraints\n    with torch.no_grad():\n        model_x1.theta.clamp_(0.01, 0.95)\n    \n    losses_x1.append(loss.item())\n    tax_rates_x1.append(model_x1.theta.item())\n    \n    if epoch % 40 == 0:\n        print(f\"Epoch {epoch:3d} | Loss: {loss.item():.4f} | Opt Tax Rate: {model_x1.theta.item():.4f}\")\n\nprint(f\"\\nFinal optimized tax rate: {model_x1.theta.item():.4f}\")\nprint(f\"Final loss: {losses_x1[-1]:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### X1: Results & Visualization\n\n# X1 Visualization\ny_final_x1, h_final_x1 = model_x1(torch.tensor(10.0))\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\naxes[0, 0].plot(losses_x1, color='blue', linewidth=2)\naxes[0, 0].set_title('X1: Loss Convergence')\naxes[0, 0].set_ylabel('Loss')\naxes[0, 0].set_xlabel('Epoch')\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].plot(tax_rates_x1, color='green', linewidth=2)\naxes[0, 1].set_title('X1: Optimal Tax Rate Evolution')\naxes[0, 1].set_ylabel('Tax Rate')\naxes[0, 1].set_xlabel('Epoch')\naxes[0, 1].grid(True, alpha=0.3)\n\naxes[1, 0].plot(y_final_x1.detach().numpy(), label='GDP (Y)', linewidth=2)\naxes[1, 0].axhline(y=100.0, color='red', linestyle='--', label='Target')\naxes[1, 0].set_title('X1: Final GDP Trajectory')\naxes[1, 0].set_ylabel('GDP')\naxes[1, 0].set_xlabel('Time Step')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\naxes[1, 1].plot(h_final_x1.detach().numpy(), color='orange', linewidth=2)\naxes[1, 1].set_title('X1: Final Wealth (H) Trajectory')\naxes[1, 1].set_ylabel('Wealth')\naxes[1, 1].set_xlabel('Time Step')\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ X1 Complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X2: Differentiable Input-Output (Leontief) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### X2: Model Definition & Calibration\n\n# X2: Differentiable Input-Output (Leontief) Model\n# Solves the \"Inverse I-O Problem\": learn technical coefficients from data\n\nclass DifferentiableIO(nn.Module):\n    \"\"\"Differentiable Leontief Input-Output Model.\"\"\"\n    \n    def __init__(self, num_sectors):\n        super(DifferentiableIO, self).__init__()\n        self.num_sectors = num_sectors\n        \n        # Technical coefficients matrix (learnable)\n        self.A_raw = nn.Parameter(torch.randn(num_sectors, num_sectors) * 0.01)\n        \n        # Climate damage parameters\n        self.tp_sensitivity = nn.Parameter(torch.tensor(2.5))\n        self.tp_threshold = nn.Parameter(torch.tensor(2.0))\n        self.gamma = nn.Parameter(torch.tensor(0.5))\n\n    def get_damage_fraction(self, temperature):\n        \"\"\"Tipping point damage function.\"\"\"\n        return 1.0 - (1.0 / (1.0 + torch.exp(self.tp_sensitivity * (temperature - self.tp_threshold))))\n\n    def get_A(self, temperature=None):\n        \"\"\"Get technical coefficients matrix, optionally damaged by climate.\"\"\"\n        A_baseline = torch.sigmoid(self.A_raw) * 0.5\n        \n        if temperature is not None:\n            damage = self.get_damage_fraction(temperature)\n            return A_baseline * (1.0 + self.gamma * damage)\n        \n        return A_baseline\n\n    def forward(self, final_demand, temperature=None):\n        \"\"\"Leontief Solution: x = (I - A)^-1 * d\"\"\"\n        A = self.get_A(temperature)\n        I = torch.eye(self.num_sectors)\n        \n        total_output = torch.linalg.solve(I - A, final_demand)\n        return total_output\n\n\n# Run X2 Experiment\nprint(\"X2: Differentiable Input-Output Model Calibration\")\nprint(\"=\" * 60)\n\n# Mock Observed Data\nobserved_x = torch.tensor([150.0, 200.0, 180.0])\nobserved_d = torch.tensor([50.0, 80.0, 60.0])\n\nmodel_x2 = DifferentiableIO(num_sectors=3)\noptimizer_x2 = optim.Adam(model_x2.parameters(), lr=0.01)\ncriterion = nn.MSELoss()\n\nprint(\"Calibrating Technical Coefficients Matrix...\\n\")\nlosses_x2 = []\n\nfor epoch in range(1001):\n    optimizer_x2.zero_grad()\n    \n    predicted_x = model_x2(observed_d)\n    loss = criterion(predicted_x, observed_x)\n    \n    loss.backward()\n    optimizer_x2.step()\n    \n    losses_x2.append(loss.item())\n    \n    if epoch % 200 == 0:\n        print(f\"Epoch {epoch:4d} | Loss: {loss.item():.6f}\")\n\nprint(f\"\\nCalibrated A matrix:\")\nwith torch.no_grad():\n    print(model_x2.get_A())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### X2: Climate Stress Test & Visualization\n\n# X2: Climate Stress Testing\nprint(\"\\nX2: Climate Stress Test (Temperature 1.1°C to 4.0°C)\")\nprint(\"=\" * 60)\n\ntemp_range = torch.linspace(1.1, 4.0, 30)\noutputs_x2 = []\ndamages_x2 = []\n\nwith torch.no_grad():\n    for t in temp_range:\n        x = model_x2(observed_d, temperature=t)\n        d = model_x2.get_damage_fraction(t)\n        outputs_x2.append(x.sum().item())\n        damages_x2.append(d.item())\n\n# Visualization\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\naxes[0].plot(losses_x2, color='blue', linewidth=2)\naxes[0].set_title('X2: Loss Convergence')\naxes[0].set_ylabel('MSE Loss')\naxes[0].set_xlabel('Epoch')\naxes[0].grid(True, alpha=0.3)\naxes[0].set_yscale('log')\n\naxes[1].plot(temp_range.numpy(), outputs_x2, color='green', linewidth=2)\naxes[1].axvline(x=2.0, color='red', linestyle='--', label='Tipping Point')\naxes[1].set_title('X2: Economic Output vs Temperature')\naxes[1].set_ylabel('Total Output')\naxes[1].set_xlabel('Temperature (°C)')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\naxes[2].plot(temp_range.numpy(), damages_x2, color='orange', linewidth=2)\naxes[2].set_title('X2: Damage Fraction vs Temperature')\naxes[2].set_ylabel('Damage (0-1)')\naxes[2].set_xlabel('Temperature (°C)')\naxes[2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ X2 Complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X3: Tropical Supply Chain (Bottlenecks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### X3: Model Definition & Optimization\n\n# X3: Tropical Supply Chain with Bottleneck Logic\n# Demonstrates min-plus algebra for supply chain resilience\n\nclass TropicalSupplyChain(nn.Module):\n    \"\"\"Differentiable supply chain using tropical (min-plus) algebra.\"\"\"\n    \n    def __init__(self, beta=20.0):\n        super(TropicalSupplyChain, self).__init__()\n        self.num_nodes = 4\n        \n        # Bill-of-Materials: Linear chain dependency\n        self.register_buffer('BOM', torch.tensor([\n            [0, 0, 0, 0],  # Node 0 (Source): No dependencies\n            [1, 0, 0, 0],  # Node 1 (Factory): Requires Node 0\n            [0, 1, 0, 0],  # Node 2 (Distributor): Requires Node 1\n            [0, 0, 1, 0]   # Node 3 (Customer): Requires Node 2\n        ], dtype=torch.float32))\n        \n        self.beta = beta\n        self.register_parameter('buffer_logits', nn.Parameter(torch.full((1, 4), -5.0)))\n\n    def soft_min(self, x, dim=-1):\n        \"\"\"Differentiable soft-min via Log-Sum-Exp.\"\"\"\n        return -(1.0 / self.beta) * torch.logsumexp(-self.beta * x, dim=dim)\n\n    def forward(self, shocks):\n        \"\"\"Propagate shocks through supply chain.\"\"\"\n        effective_capacity = torch.clamp(\n            shocks + torch.sigmoid(self.buffer_logits),\n            0.0, 1.0\n        )\n        \n        node_outputs = [effective_capacity[:, 0]]\n        \n        for i in range(1, self.num_nodes):\n            current_cap = effective_capacity[:, i]\n            upstream_in = node_outputs[i - 1]\n            combined = torch.stack([current_cap, upstream_in], dim=-1)\n            node_outputs.append(self.soft_min(combined, dim=-1))\n        \n        return torch.stack(node_outputs, dim=1)\n\n\n# Run X3 Experiment\nprint(\"X3: Tropical Supply Chain - Reverse Stress Test\")\nprint(\"=\" * 60)\n\nmodel_x3 = TropicalSupplyChain(beta=30.0)\noptimizer_x3 = optim.Adam(model_x3.parameters(), lr=0.1)\n\nshocks = torch.tensor([[0.2, 1.0, 1.0, 1.0]])\ntarget_customer_output = 0.8\n\nprint(\"Optimizing buffer allocation to maintain customer output at 80%...\\n\")\nlosses_x3 = []\nbuffer_evolution_x3 = []\nnodes = [\"Source\", \"Factory\", \"Distributor\", \"Customer\"]\n\nfor epoch in range(151):\n    optimizer_x3.zero_grad()\n    \n    outputs = model_x3(shocks)\n    customer_output = outputs[0, 3]\n    \n    loss_gap = (customer_output - target_customer_output)**2\n    loss_budget = 0.01 * torch.sum(torch.sigmoid(model_x3.buffer_logits))\n    total_loss = loss_gap + loss_budget\n    \n    total_loss.backward()\n    optimizer_x3.step()\n    \n    losses_x3.append(total_loss.item())\n    buffer_evolution_x3.append(torch.sigmoid(model_x3.buffer_logits).detach().numpy().flatten())\n    \n    if epoch % 50 == 0:\n        print(f\"Epoch {epoch:3d} | Loss: {total_loss.item():.6f} | Customer: {customer_output.item():.4f}\")\n\nfinal_buffers = torch.sigmoid(model_x3.buffer_logits).detach().numpy().flatten()\nprint(f\"\\nOptimal Buffer Allocation:\")\nfor i, name in enumerate(nodes):\n    print(f\"  {name:12}: {final_buffers[i]:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### X3: Results & Visualization\n\n# X3 Visualization\nbuffer_evolution_x3_array = np.array(buffer_evolution_x3)\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\naxes[0].plot(losses_x3, linewidth=2, color='blue')\naxes[0].set_title('X3: Loss Convergence')\naxes[0].set_ylabel('Loss')\naxes[0].set_xlabel('Epoch')\naxes[0].grid(True, alpha=0.3)\n\nfor i, name in enumerate(nodes):\n    axes[1].plot(buffer_evolution_x3_array[:, i], label=name, linewidth=2)\n\naxes[1].set_title('X3: Buffer Evolution')\naxes[1].set_ylabel('Buffer Size')\naxes[1].set_xlabel('Epoch')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ X3 Complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X4: Differentiable Green-SFC (Full Integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### X4: Model Definition & Training\n\n# X4: Differentiable Green-SFC with Climate Coupling\n# Full three-layer architecture: Physical → Structural → Financial\n\nclass GreenSFC(nn.Module):\n    \"\"\"Full Green-SFC with climate, structure, and finance layers.\"\"\"\n    \n    def __init__(self, num_sectors=3, beta=20.0):\n        super(GreenSFC, self).__init__()\n        self.num_sectors = num_sectors\n        self.beta = beta\n        \n        # Layer 1: Physical (Climate)\n        self.tp_threshold = nn.Parameter(torch.tensor(2.0))\n        self.tp_sensitivity = nn.Parameter(torch.tensor(3.5))\n        \n        # Layer 2: Structural (Production)\n        self.A_base = nn.Parameter(torch.eye(num_sectors) * 0.15 + torch.randn(num_sectors, num_sectors) * 0.02)\n        self.gamma = nn.Parameter(torch.ones(num_sectors) * 0.45)\n        \n        # Layer 3: Financial (Policy)\n        self.tax_rate = nn.Parameter(torch.tensor(0.20))\n        self.green_investment_prop = nn.Parameter(torch.tensor(0.02))\n        self.gov_spend = nn.Parameter(torch.tensor(50.0))\n        \n        self.alpha1 = 0.6\n        self.alpha2 = 0.05\n\n    def get_damage_fraction(self, temp):\n        \"\"\"Climate damage function.\"\"\"\n        return 1.0 / (1.0 + torch.exp(-self.tp_sensitivity * (temp - self.tp_threshold)))\n\n    def forward(self, temp_trajectory):\n        \"\"\"Simulate through temperature path.\"\"\"\n        gdp_hist = []\n        co2_hist = []\n        wealth_hist = []\n        \n        h = torch.tensor(100.0)\n        \n        for temp in temp_trajectory:\n            damage = self.get_damage_fraction(temp)\n            A_current = torch.sigmoid(self.A_base) * (1.0 + self.gamma * damage)\n            \n            theta = torch.clamp(self.tax_rate, 0.05, 0.55)\n            abatement_spending = self.green_investment_prop * 100.0\n            \n            denominator = 1.0 - self.alpha1 * (1.0 - theta)\n            numerator = self.gov_spend + abatement_spending + (self.alpha2 * h)\n            y = numerator / denominator\n            \n            abatement_efficiency = torch.sqrt(torch.clamp(self.green_investment_prop, 0.0, 1.0))\n            emissions = y * (1.0 - abatement_efficiency)\n            \n            yd = y * (1.0 - theta)\n            consumption = self.alpha1 * yd + self.alpha2 * h\n            h = h + (yd - consumption)\n            \n            gdp_hist.append(y)\n            co2_hist.append(emissions)\n            wealth_hist.append(h)\n        \n        return torch.stack(gdp_hist), torch.stack(co2_hist), torch.stack(wealth_hist)\n\n\n# Run X4 Experiment\nprint(\"X4: Differentiable Green-SFC Optimization\")\nprint(\"=\" * 60)\n\nmodel_x4 = GreenSFC()\noptimizer_x4 = optim.Adam(model_x4.parameters(), lr=0.03)\n\ntemp_trajectory = torch.linspace(1.2, 3.5, 50)\ntarget_gdp = 180.0\ntarget_co2 = 0.0\n\nprint(\"Running multi-objective optimization...\\n\")\nlosses_x4 = []\ngdp_means_x4 = []\ntax_rates_x4 = []\ngreen_invests_x4 = []\n\nfor epoch in range(201):\n    optimizer_x4.zero_grad()\n    \n    y_hist, co2_hist, wealth_hist = model_x4(temp_trajectory)\n    \n    loss_gdp = torch.mean((y_hist - target_gdp)**2)\n    loss_co2 = torch.mean(co2_hist**2) * 20.0\n    loss_stability = torch.var(wealth_hist) * 0.1\n    total_loss = loss_gdp + loss_co2 + loss_stability\n    \n    total_loss.backward()\n    optimizer_x4.step()\n    \n    losses_x4.append(total_loss.item())\n    gdp_means_x4.append(y_hist.mean().item())\n    tax_rates_x4.append(model_x4.tax_rate.item())\n    green_invests_x4.append(model_x4.green_investment_prop.item())\n    \n    if epoch % 50 == 0:\n        print(f\"Epoch {epoch:3d} | Loss: {total_loss.item():.4f} | Tax: {model_x4.tax_rate.item():.2%} | Green: {model_x4.green_investment_prop.item():.3%}\")\n\nprint(f\"\\nOptimization Complete!\")\nprint(f\"Final tax rate: {model_x4.tax_rate.item():.2%}\")\nprint(f\"Final green investment: {model_x4.green_investment_prop.item():.3%}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### X4: Results & Visualization\n\n# X4 Visualization\nwith torch.no_grad():\n    y_final_x4, co2_final_x4, w_final_x4 = model_x4(temp_trajectory)\n\nfig = plt.figure(figsize=(16, 10))\ngs = GridSpec(3, 3, figure=fig)\n\nax1 = fig.add_subplot(gs[0, 0])\nax1.plot(losses_x4, linewidth=2, color='blue')\nax1.set_title('X4: Loss Convergence')\nax1.set_ylabel('Loss')\nax1.grid(True, alpha=0.3)\n\nax2 = fig.add_subplot(gs[0, 1])\nax2.plot(y_final_x4.detach().numpy(), linewidth=2, color='green')\nax2.axhline(y=target_gdp, color='red', linestyle='--')\nax2.set_title('X4: GDP Trajectory')\nax2.set_ylabel('GDP')\nax2.grid(True, alpha=0.3)\n\nax3 = fig.add_subplot(gs[0, 2])\nax3.plot(co2_final_x4.detach().numpy(), linewidth=2, color='orange')\nax3.set_title('X4: Emissions Path')\nax3.set_ylabel('CO₂')\nax3.grid(True, alpha=0.3)\n\nax4 = fig.add_subplot(gs[1, 0])\nax4.plot(w_final_x4.detach().numpy(), linewidth=2, color='purple')\nax4.set_title('X4: Wealth Stability')\nax4.set_ylabel('Wealth')\nax4.grid(True, alpha=0.3)\n\nax5 = fig.add_subplot(gs[1, 1])\nax5.plot(temp_trajectory.numpy(), linewidth=2, color='red')\nax5.axhline(y=model_x4.tp_threshold.item(), color='darkred', linestyle='--')\nax5.set_title('X4: Temperature Scenario')\nax5.set_ylabel('Temperature (°C)')\nax5.grid(True, alpha=0.3)\n\nax6 = fig.add_subplot(gs[1, 2])\nax6.plot(tax_rates_x4, linewidth=2, color='steelblue')\nax6.set_title('X4: Tax Rate Evolution')\nax6.set_ylabel('Tax Rate')\nax6.grid(True, alpha=0.3)\n\nax7 = fig.add_subplot(gs[2, 0])\nax7.plot(green_invests_x4, linewidth=2, color='green')\nax7.set_title('X4: Green Investment')\nax7.set_ylabel('% of GDP')\nax7.grid(True, alpha=0.3)\n\nax8 = fig.add_subplot(gs[2, 1])\nax8.plot(gdp_means_x4, linewidth=2, color='darkgreen')\nax8.axhline(y=target_gdp, color='red', linestyle='--')\nax8.set_title('X4: Mean GDP Evolution')\nax8.set_ylabel('Mean GDP')\nax8.grid(True, alpha=0.3)\n\nax9 = fig.add_subplot(gs[2, 2])\nax9.scatter(y_final_x4.detach().numpy(), co2_final_x4.detach().numpy(),\n           c=range(len(y_final_x4)), cmap='viridis', s=50)\nax9.set_title('X4: Economic-Emissions Phase Space')\nax9.set_xlabel('GDP')\nax9.set_ylabel('CO₂')\nax9.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ X4 Complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X5: Stimulus Trigger Annealing (Variable β)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### X5: Model Definition & Experiments\n\n# X5: Minimal Economic Trigger with Variable β Annealing\n# Demonstrates chattering problem and how β solves it\n\nclass StimulusModel(nn.Module):\n    \"\"\"Minimal model with policy trigger controlled by β.\"\"\"\n    \n    def __init__(self, beta=1.0):\n        super(StimulusModel, self).__init__()\n        self.u_target = 0.05\n        self.recovery_rate = 0.1\n        self.decay_rate = 0.05\n        \n        self.u_trigger = nn.Parameter(torch.tensor(0.06))\n        self.beta = beta\n\n    def get_trigger_response(self, u):\n        \"\"\"Sigmoid trigger controlled by β.\"\"\"\n        trigger_signal = torch.sigmoid(self.beta * (u - self.u_trigger))\n        g = 2.0 * trigger_signal\n        return g\n\n    def forward(self, u_initial, steps=100):\n        \"\"\"Simulate unemployment dynamics.\"\"\"\n        u = u_initial\n        u_history = []\n        g_history = []\n        \n        for _ in range(steps):\n            g = self.get_trigger_response(u)\n            u_next = u + (self.decay_rate - self.recovery_rate * g)\n            u = torch.clamp(u_next, 0.01, 0.20)\n            \n            u_history.append(u)\n            g_history.append(g)\n        \n        return torch.stack(u_history), torch.stack(g_history)\n\n    def set_temperature(self, T):\n        \"\"\"Set inverse temperature β = 1/T.\"\"\"\n        self.beta = 1.0 / max(T, 0.01)\n\n\n# X5 Experiment 1: Chattering vs Stability\nprint(\"X5: Minimal Economic Trigger with Variable β\")\nprint(\"=\" * 60)\nprint(\"\\nExperiment 1: Chattering vs. Stability\")\nprint(\"-\" * 60)\n\nhard_model_x5 = StimulusModel(beta=100.0)\nu_hard_x5, g_hard_x5 = hard_model_x5(torch.tensor(0.05), steps=100)\n\nsoft_model_x5 = StimulusModel(beta=5.0)\nu_soft_x5, g_soft_x5 = soft_model_x5(torch.tensor(0.05), steps=100)\n\nprint(f\"Hard Case (β=100):\")\nprint(f\"  Mean U: {u_hard_x5.mean():.4f}, Std: {u_hard_x5.std():.4f}\")\nprint(f\"  Mean G: {g_hard_x5.mean():.4f}, Std: {g_hard_x5.std():.4f}\")\nprint()\nprint(f\"Soft Case (β=5):\")\nprint(f\"  Mean U: {u_soft_x5.mean():.4f}, Std: {u_soft_x5.std():.4f}\")\nprint(f\"  Mean G: {g_soft_x5.mean():.4f}, Std: {g_soft_x5.std():.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### X5: Experiment 2 - Fixed β Optimization\n\n# X5 Experiment 2: Fixed β Optimization\nprint(\"\\nExperiment 2: Optimization with Fixed β=5\")\nprint(\"-\" * 60)\n\nmodel_opt_x5 = StimulusModel(beta=5.0)\noptimizer_opt_x5 = optim.Adam(model_opt_x5.parameters(), lr=0.001)\n\nlosses_opt_x5 = []\ntriggers_opt_x5 = []\n\nfor epoch in range(200):\n    optimizer_opt_x5.zero_grad()\n    u_hist, _ = model_opt_x5(torch.tensor(0.05), steps=100)\n    loss = torch.mean((u_hist - 0.05)**2)\n    loss.backward()\n    optimizer_opt_x5.step()\n    \n    losses_opt_x5.append(loss.item())\n    triggers_opt_x5.append(model_opt_x5.u_trigger.item())\n    \n    if epoch % 50 == 0:\n        print(f\"  Epoch {epoch:3d}: Loss = {loss.item():.6f}, U_trigger = {model_opt_x5.u_trigger.item():.4f}\")\n\nprint(f\"\\nOptimized trigger: {model_opt_x5.u_trigger.item():.4f}\")\n\nwith torch.no_grad():\n    u_opt_x5, g_opt_x5 = model_opt_x5(torch.tensor(0.05), steps=100)\nprint(f\"Final mean U: {u_opt_x5.mean():.4f}, Std: {u_opt_x5.std():.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### X5: Experiment 3 - Annealing Schedule\n\n# X5 Experiment 3: Annealing\nprint(\"\\nExperiment 3: Optimization with Annealing β\")\nprint(\"-\" * 60)\n\nmodel_anneal_x5 = StimulusModel(beta=1.0)\noptimizer_anneal_x5 = optim.Adam(model_anneal_x5.parameters(), lr=0.002)\n\nlosses_anneal_x5 = []\nbetas_anneal_x5 = []\ntriggers_anneal_x5 = []\n\nfor epoch in range(300):\n    # Anneal schedule\n    if epoch < 50:\n        model_anneal_x5.set_temperature(1.0)\n    elif epoch < 150:\n        t = (epoch - 50) / 100.0\n        T = 1.0 - 0.8 * t\n        model_anneal_x5.set_temperature(T)\n    else:\n        model_anneal_x5.set_temperature(0.05)\n    \n    optimizer_anneal_x5.zero_grad()\n    u_hist, _ = model_anneal_x5(torch.tensor(0.05), steps=100)\n    loss = torch.mean((u_hist - 0.05)**2)\n    loss.backward()\n    optimizer_anneal_x5.step()\n    \n    losses_anneal_x5.append(loss.item())\n    betas_anneal_x5.append(model_anneal_x5.beta)\n    triggers_anneal_x5.append(model_anneal_x5.u_trigger.item())\n    \n    if epoch % 50 == 0:\n        print(f\"  Epoch {epoch:3d}: β = {model_anneal_x5.beta:6.2f}, Loss = {loss.item():.6f}\")\n\nprint(f\"\\nRobustness Check at Different β:\")\nwith torch.no_grad():\n    for test_beta in [1.0, 5.0, 20.0, 100.0]:\n        model_anneal_x5.set_temperature(1.0 / test_beta)\n        u_test, _ = model_anneal_x5(torch.tensor(0.05), steps=100)\n        print(f\"  β = {test_beta:6.1f}: Mean U = {u_test.mean():.4f}, Std = {u_test.std():.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### X5: Results & Visualization\n\n# X5 Visualization\nfig = plt.figure(figsize=(16, 10))\ngs = GridSpec(3, 3, figure=fig)\n\n# Exp 1: Chattering vs Stability\nax1 = fig.add_subplot(gs[0, 0])\nax1.plot(u_hard_x5.detach().numpy(), label='Hard (β=100)', linewidth=2, alpha=0.7)\nax1.plot(u_soft_x5.detach().numpy(), label='Soft (β=5)', linewidth=2)\nax1.axhline(y=0.05, color='red', linestyle='--', label='Target')\nax1.set_title('Exp1: Chattering vs Stability')\nax1.set_ylabel('Unemployment')\nax1.legend(fontsize=8)\nax1.grid(True, alpha=0.3)\n\nax2 = fig.add_subplot(gs[0, 1])\nax2.plot(g_hard_x5.detach().numpy(), label='Hard G', alpha=0.7, linewidth=2)\nax2.plot(g_soft_x5.detach().numpy(), label='Soft G', linewidth=2)\nax2.set_title('Exp1: Government Spending')\nax2.set_ylabel('Spending Level')\nax2.legend(fontsize=8)\nax2.grid(True, alpha=0.3)\n\nax3 = fig.add_subplot(gs[0, 2])\nax3.bar(['Hard\\n(β=100)', 'Soft\\n(β=5)'],\n        [u_hard_x5.std().item(), u_soft_x5.std().item()],\n        color=['red', 'green'], alpha=0.7)\nax3.set_title('Exp1: Volatility (Std Dev)')\nax3.set_ylabel('Std Dev')\n\n# Exp 2: Fixed β optimization\nax4 = fig.add_subplot(gs[1, 0])\nax4.plot(losses_opt_x5, linewidth=2, color='blue')\nax4.set_title('Exp2: Loss Convergence')\nax4.set_ylabel('Loss')\nax4.grid(True, alpha=0.3)\n\nax5 = fig.add_subplot(gs[1, 1])\nax5.plot(triggers_opt_x5, linewidth=2, color='green')\nax5.set_title('Exp2: Trigger Evolution')\nax5.set_ylabel('U_trigger')\nax5.grid(True, alpha=0.3)\n\nax6 = fig.add_subplot(gs[1, 2])\nax6.plot(u_opt_x5.detach().numpy(), label='Optimized', linewidth=2)\nax6.axhline(y=0.05, color='red', linestyle='--')\nax6.set_title('Exp2: Final Unemployment')\nax6.set_ylabel('Unemployment')\nax6.legend(fontsize=8)\nax6.grid(True, alpha=0.3)\n\n# Exp 3: Annealing\nax7 = fig.add_subplot(gs[2, 0])\nax7.plot(losses_anneal_x5, linewidth=2, color='purple')\nax7.set_title('Exp3: Loss with Annealing')\nax7.set_ylabel('Loss')\nax7.set_xlabel('Epoch')\nax7.grid(True, alpha=0.3)\n\nax8 = fig.add_subplot(gs[2, 1])\nax8_twin = ax8.twinx()\nax8.plot(triggers_anneal_x5, linewidth=2, color='orange', label='U_trigger')\nax8_twin.plot(betas_anneal_x5, linewidth=2, color='blue', alpha=0.5, label='β')\nax8.set_title('Exp3: Trigger & Temperature')\nax8.set_ylabel('U_trigger', color='orange')\nax8_twin.set_ylabel('β', color='blue')\nax8.set_xlabel('Epoch')\nax8.grid(True, alpha=0.3)\n\nax9 = fig.add_subplot(gs[2, 2])\nax9.plot(betas_anneal_x5, linewidth=2, color='red')\nax9.axvline(x=50, color='gray', linestyle='--', alpha=0.5)\nax9.axvline(x=150, color='gray', linestyle='--', alpha=0.5)\nax9.set_title('Exp3: β Annealing Schedule')\nax9.set_ylabel('β (Inverse Temperature)')\nax9.set_xlabel('Epoch')\nax9.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ X5 Complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Key Takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY: DIFFERENTIABLE SFC EXPERIMENTS X1-X5\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"X1: Differentiable SIM Model (PyTorch)\")\n",
    "print(\"   - Baseline SFC model with learnable parameters\")\n",
    "print(\"   - Policy optimization via gradient descent\")\n",
    "print(f\"   - Achieved target GDP: {y_final_x1.mean():.1f} (target: 100)\")\n",
    "print()\n",
    "print(\"X2: Differentiable Input-Output (Leontief) Model\")\n",
    "print(\"   - Inverse I-O calibration from data\")\n",
    "print(\"   - Climate damage feedback integrated\")\n",
    "print(f\"   - Shows economic collapse as temperature rises\")\n",
    "print()\n",
    "print(\"X3: Tropical Supply Chain (Bottlenecks)\")\n",
    "print(\"   - Min-plus algebra for bottleneck logic\")\n",
    "print(\"   - Optimal buffer placement via optimization\")\n",
    "print(f\"   - Source buffer: {final_buffers[0]:.4f} (most critical node)\")\n",
    "print()\n",
    "print(\"X4: Differentiable Green-SFC (Full Integration)\")\n",
    "print(\"   - Three-layer architecture (Physical → Structural → Financial)\")\n",
    "print(\"   - Multi-objective optimization (GDP, emissions, stability)\")\n",
    "print(f\"   - Optimal tax rate: {model_x4.tax_rate.item():.2%}\")\n",
    "print(f\"   - Green investment: {model_x4.green_investment_prop.item():.3%} of GDP\")\n",
    "print()\n",
    "print(\"X5: Stimulus Trigger Annealing (Variable β)\")\n",
    "print(\"   - Minimal model demonstrating chattering problem\")\n",
    "print(\"   - Variable β solution: start fuzzy, cool gradually\")\n",
    "print(f\"   - Hard trigger volatility: {u_hard_x5.std():.4f}\")\n",
    "print(f\"   - Soft trigger volatility: {u_soft_x5.std():.4f}\")\n",
    "print(f\"   - Annealing robustness: Works at all β values\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"1. CHATTERING PROBLEM (X5):\")\n",
    "print(\"   Binary triggers in discrete simulations create oscillations.\")\n",
    "print(\"   Your Stella model exhibits this documented behavior.\")\n",
    "print()\n",
    "print(\"2. VARIABLE β SOLUTION:\")\n",
    "print(\"   Start fuzzy (low β) for smooth optimization.\")\n",
    "print(\"   Cool gradually (increase β) to sharpen constraints.\")\n",
    "print(\"   End precise (high β) while maintaining stability.\")\n",
    "print()\n",
    "print(\"3. MULTI-LAYER INTEGRATION (X4):\")\n",
    "print(\"   Physical: Climate damage via sigmoid tipping point\")\n",
    "print(\"   Structural: Technical coefficients respond to temperature\")\n",
    "print(\"   Financial: SFC accounting with policy optimization\")\n",
    "print()\n",
    "print(\"4. PARETO FRONTIER:\")\n",
    "print(\"   Balancing unemployment, emissions, and stability\")\n",
    "print(\"   Trade-offs become explicit and quantifiable\")\n",
    "print(\"   Policy recommendations are transparent\")\n",
    "print()\n",
    "print(\"5. PATH FORWARD:\")\n",
    "print(\"   Use Stella parser (lib/stella_parser.py) to extract LowGrow\")\n",
    "print(\"   Convert to PyTorch with variable β annealing\")\n",
    "print(\"   Eliminate oscillations automatically\")\n",
    "print(\"   Discover optimal climate-economic policies\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}